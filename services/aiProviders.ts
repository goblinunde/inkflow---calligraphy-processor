/**
 * å¤š AI æä¾›å•†ç»Ÿä¸€æœåŠ¡æ¥å£
 * ğŸ’¡ æ”¯æŒ Geminiã€OpenAIã€DeepSeekã€Qwenã€Groq (LLaMA) ç­‰
 */

// ==================== ç±»å‹å®šä¹‰ ====================

export type AIProvider = 'gemini' | 'openai' | 'deepseek' | 'qwen' | 'groq';

export interface AIProviderConfig {
    id: AIProvider;
    name: string;
    description: string;
    supportsImageEdit: boolean;
    baseUrl: string;
    models: string[];
    defaultModel: string;
}

export interface AIConfig {
    provider: AIProvider;
    apiKey: string;
    model?: string;
}

export interface ImageRestoreResult {
    success: boolean;
    imageData?: string; // base64 data URL
    suggestion?: string; // å¯¹äºä¸æ”¯æŒå›¾åƒç¼–è¾‘çš„æä¾›å•†ï¼Œè¿”å›æ–‡å­—å»ºè®®
    error?: string;
}

// ==================== æä¾›å•†é…ç½® ====================

export const AI_PROVIDERS: Record<AIProvider, AIProviderConfig> = {
    gemini: {
        id: 'gemini',
        name: 'Google Gemini',
        description: 'æ”¯æŒå›¾åƒç”Ÿæˆ/ç¼–è¾‘',
        supportsImageEdit: true,
        baseUrl: 'https://generativelanguage.googleapis.com',
        models: ['gemini-2.5-flash-image', 'gemini-2.0-flash', 'gemini-1.5-pro'],
        defaultModel: 'gemini-2.5-flash-image'
    },
    openai: {
        id: 'openai',
        name: 'OpenAI',
        description: 'GPT-4o å›¾åƒç†è§£ + DALL-E ç¼–è¾‘',
        supportsImageEdit: true,
        baseUrl: 'https://api.openai.com',
        models: ['gpt-4o', 'gpt-4o-mini', 'dall-e-3'],
        defaultModel: 'gpt-4o'
    },
    deepseek: {
        id: 'deepseek',
        name: 'DeepSeek',
        description: 'ä»…æ–‡æœ¬åˆ†æï¼ˆè¿”å›å¤„ç†å»ºè®®ï¼‰',
        supportsImageEdit: false,
        baseUrl: 'https://api.deepseek.com',
        models: ['deepseek-chat', 'deepseek-reasoner'],
        defaultModel: 'deepseek-chat'
    },
    qwen: {
        id: 'qwen',
        name: 'Qwen (é€šä¹‰åƒé—®)',
        description: 'è§†è§‰ç†è§£ä¸ºä¸»',
        supportsImageEdit: false,
        baseUrl: 'https://dashscope.aliyuncs.com',
        models: ['qwen-vl-max', 'qwen-vl-plus'],
        defaultModel: 'qwen-vl-max'
    },
    groq: {
        id: 'groq',
        name: 'Groq (LLaMA)',
        description: 'ä»…æ–‡æœ¬ï¼ˆé«˜é€Ÿæ¨ç†ï¼‰',
        supportsImageEdit: false,
        baseUrl: 'https://api.groq.com',
        models: ['llama-3.3-70b-versatile', 'llama-3.1-8b-instant'],
        defaultModel: 'llama-3.3-70b-versatile'
    }
};

// ==================== Token ç®¡ç† ====================

const TOKEN_STORAGE_KEY = 'inkflow-ai-tokens';

export interface StoredTokens {
    [key: string]: string; // provider -> token
}

export const saveToken = (provider: AIProvider, token: string): void => {
    const tokens = loadTokens();
    tokens[provider] = token;
    localStorage.setItem(TOKEN_STORAGE_KEY, JSON.stringify(tokens));
};

export const loadTokens = (): StoredTokens => {
    try {
        const stored = localStorage.getItem(TOKEN_STORAGE_KEY);
        return stored ? JSON.parse(stored) : {};
    } catch {
        return {};
    }
};

export const getToken = (provider: AIProvider): string | null => {
    const tokens = loadTokens();
    return tokens[provider] || null;
};

export const removeToken = (provider: AIProvider): void => {
    const tokens = loadTokens();
    delete tokens[provider];
    localStorage.setItem(TOKEN_STORAGE_KEY, JSON.stringify(tokens));
};

// ==================== å›¾åƒä¿®å¤ Prompt ====================

const IMAGE_RESTORE_PROMPT = `This is an image of Chinese calligraphy (signatures or characters). 
Please RESTORE this image:
1. Keep the exact shape and style of the text.
2. Make the strokes solid black and high contrast.
3. Remove any paper texture, noise, or watermarks, making the background pure white.
4. Fix any broken or jagged edges in the strokes to make them look like smooth ink.
Return ONLY the restored image.`;

const TEXT_ANALYSIS_PROMPT = `This is an image of Chinese calligraphy. 
Analyze the image quality and provide specific suggestions for:
1. How to improve stroke clarity
2. How to remove background noise
3. Recommended threshold values for binarization
4. Any detected issues with the image
Respond in Chinese.`;

// ==================== Gemini å®ç° ====================

async function restoreWithGemini(base64Image: string, apiKey: string, model: string): Promise<ImageRestoreResult> {
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, '');
    const mimeType = base64Image.match(/data:image\/(.*?);base64/)?.[1] || 'png';

    try {
        const response = await fetch(
            `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`,
            {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    contents: [{
                        parts: [
                            { inlineData: { mimeType: `image/${mimeType}`, data: cleanBase64 } },
                            { text: IMAGE_RESTORE_PROMPT }
                        ]
                    }],
                    generationConfig: {
                        responseModalities: ["image", "text"]
                    }
                })
            }
        );

        if (!response.ok) {
            const error = await response.json();
            throw new Error(error.error?.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        const candidates = data.candidates;

        if (candidates?.[0]?.content?.parts) {
            for (const part of candidates[0].content.parts) {
                if (part.inlineData?.data) {
                    return {
                        success: true,
                        imageData: `data:image/png;base64,${part.inlineData.data}`
                    };
                }
            }
        }

        return { success: false, error: 'AI æœªè¿”å›å›¾åƒï¼Œå¯èƒ½åªè¿”å›äº†æ–‡å­—æè¿°' };
    } catch (error) {
        return { success: false, error: (error as Error).message };
    }
}

// ==================== OpenAI å®ç° ====================

async function restoreWithOpenAI(base64Image: string, apiKey: string, model: string): Promise<ImageRestoreResult> {
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, '');
    const mimeType = base64Image.match(/data:image\/(.*?);base64/)?.[1] || 'png';

    try {
        // ğŸ’¡ GPT-4o æ”¯æŒå›¾åƒç†è§£ï¼Œä½†ä¸ç›´æ¥ç”Ÿæˆå›¾åƒ
        // æˆ‘ä»¬å…ˆè·å–åˆ†æå»ºè®®ï¼Œç„¶åå¯ä»¥è°ƒç”¨ DALL-E æˆ–è¿”å›å»ºè®®
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model: model,
                messages: [{
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: { url: `data:image/${mimeType};base64,${cleanBase64}` }
                        },
                        { type: 'text', text: TEXT_ANALYSIS_PROMPT }
                    ]
                }],
                max_tokens: 1000
            })
        });

        if (!response.ok) {
            const error = await response.json();
            throw new Error(error.error?.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        const content = data.choices?.[0]?.message?.content;

        if (content) {
            return {
                success: true,
                suggestion: content
            };
        }

        return { success: false, error: 'OpenAI æœªè¿”å›æœ‰æ•ˆå“åº”' };
    } catch (error) {
        return { success: false, error: (error as Error).message };
    }
}

// ==================== DeepSeek å®ç° ====================

async function analyzeWithDeepSeek(base64Image: string, apiKey: string, model: string): Promise<ImageRestoreResult> {
    try {
        // ğŸ’¡ DeepSeek ä¸æ”¯æŒå›¾åƒè¾“å…¥ï¼Œåªèƒ½æä¾›é€šç”¨å»ºè®®
        const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model: model,
                messages: [{
                    role: 'user',
                    content: 'æˆ‘æœ‰ä¸€å¼ ä¸­å›½ä¹¦æ³•å›¾ç‰‡éœ€è¦å¤„ç†ï¼Œè¯·æä¾›ä»¥ä¸‹å»ºè®®ï¼š\n1. å¦‚ä½•æé«˜ç¬”ç”»æ¸…æ™°åº¦\n2. å¦‚ä½•å»é™¤èƒŒæ™¯å™ªå£°\n3. æ¨èçš„äºŒå€¼åŒ–é˜ˆå€¼èŒƒå›´\n4. å¸¸è§çš„å›¾åƒå¤„ç†æŠ€å·§'
                }],
                max_tokens: 1000
            })
        });

        if (!response.ok) {
            const error = await response.json();
            throw new Error(error.error?.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        const content = data.choices?.[0]?.message?.content;

        if (content) {
            return {
                success: true,
                suggestion: content
            };
        }

        return { success: false, error: 'DeepSeek æœªè¿”å›æœ‰æ•ˆå“åº”' };
    } catch (error) {
        return { success: false, error: (error as Error).message };
    }
}

// ==================== Qwen å®ç° ====================

async function analyzeWithQwen(base64Image: string, apiKey: string, model: string): Promise<ImageRestoreResult> {
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, '');

    try {
        const response = await fetch('https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model: model,
                messages: [{
                    role: 'user',
                    content: [
                        { type: 'image_url', image_url: { url: `data:image/png;base64,${cleanBase64}` } },
                        { type: 'text', text: TEXT_ANALYSIS_PROMPT }
                    ]
                }]
            })
        });

        if (!response.ok) {
            const error = await response.json();
            throw new Error(error.error?.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        const content = data.choices?.[0]?.message?.content;

        if (content) {
            return {
                success: true,
                suggestion: content
            };
        }

        return { success: false, error: 'Qwen æœªè¿”å›æœ‰æ•ˆå“åº”' };
    } catch (error) {
        return { success: false, error: (error as Error).message };
    }
}

// ==================== Groq (LLaMA) å®ç° ====================

async function analyzeWithGroq(base64Image: string, apiKey: string, model: string): Promise<ImageRestoreResult> {
    try {
        // ğŸ’¡ Groq ä¸æ”¯æŒå›¾åƒè¾“å…¥ï¼Œåªèƒ½æä¾›é€šç”¨å»ºè®®
        const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model: model,
                messages: [{
                    role: 'user',
                    content: 'æˆ‘æœ‰ä¸€å¼ ä¸­å›½ä¹¦æ³•å›¾ç‰‡éœ€è¦å¤„ç†ï¼Œè¯·æä¾›ä»¥ä¸‹å»ºè®®ï¼š\n1. å¦‚ä½•æé«˜ç¬”ç”»æ¸…æ™°åº¦\n2. å¦‚ä½•å»é™¤èƒŒæ™¯å™ªå£°\n3. æ¨èçš„äºŒå€¼åŒ–é˜ˆå€¼èŒƒå›´\n4. å¸¸è§çš„å›¾åƒå¤„ç†æŠ€å·§'
                }],
                max_tokens: 1000
            })
        });

        if (!response.ok) {
            const error = await response.json();
            throw new Error(error.error?.message || `HTTP ${response.status}`);
        }

        const data = await response.json();
        const content = data.choices?.[0]?.message?.content;

        if (content) {
            return {
                success: true,
                suggestion: content
            };
        }

        return { success: false, error: 'Groq æœªè¿”å›æœ‰æ•ˆå“åº”' };
    } catch (error) {
        return { success: false, error: (error as Error).message };
    }
}

// ==================== ç»Ÿä¸€è°ƒç”¨æ¥å£ ====================

export async function restoreImageWithAI(
    base64Image: string,
    config: AIConfig
): Promise<ImageRestoreResult> {
    const { provider, apiKey, model } = config;
    const providerConfig = AI_PROVIDERS[provider];
    const selectedModel = model || providerConfig.defaultModel;

    if (!apiKey) {
        return { success: false, error: 'è¯·å…ˆé…ç½® API Token' };
    }

    switch (provider) {
        case 'gemini':
            return restoreWithGemini(base64Image, apiKey, selectedModel);
        case 'openai':
            return restoreWithOpenAI(base64Image, apiKey, selectedModel);
        case 'deepseek':
            return analyzeWithDeepSeek(base64Image, apiKey, selectedModel);
        case 'qwen':
            return analyzeWithQwen(base64Image, apiKey, selectedModel);
        case 'groq':
            return analyzeWithGroq(base64Image, apiKey, selectedModel);
        default:
            return { success: false, error: 'ä¸æ”¯æŒçš„ AI æä¾›å•†' };
    }
}

// ==================== Token éªŒè¯ ====================

export async function validateToken(provider: AIProvider, apiKey: string): Promise<boolean> {
    try {
        switch (provider) {
            case 'gemini': {
                const response = await fetch(
                    `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`
                );
                return response.ok;
            }
            case 'openai': {
                const response = await fetch('https://api.openai.com/v1/models', {
                    headers: { 'Authorization': `Bearer ${apiKey}` }
                });
                return response.ok;
            }
            case 'deepseek': {
                const response = await fetch('https://api.deepseek.com/v1/models', {
                    headers: { 'Authorization': `Bearer ${apiKey}` }
                });
                return response.ok;
            }
            case 'qwen': {
                // Qwen API éœ€è¦å®é™…è°ƒç”¨æ‰èƒ½éªŒè¯
                return apiKey.length > 10;
            }
            case 'groq': {
                const response = await fetch('https://api.groq.com/openai/v1/models', {
                    headers: { 'Authorization': `Bearer ${apiKey}` }
                });
                return response.ok;
            }
            default:
                return false;
        }
    } catch {
        return false;
    }
}
