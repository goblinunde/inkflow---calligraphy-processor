/**
 * OpenCV.js Service Wrapper
 * ğŸ’¡ æä¾›å¯¹ OpenCV WebAssembly åº“çš„å°è£…ï¼Œå®ç° PS çº§åˆ«å›¾åƒå¤„ç†
 */
import cv from '@techstark/opencv-js';

// ğŸ’¡ OpenCV.js éœ€è¦å¼‚æ­¥åŠ è½½ï¼Œä½¿ç”¨ Promise ç®¡ç†åŠ è½½çŠ¶æ€
let cvReady = false;
let cvReadyPromise: Promise<void>;

export const initOpenCV = (): Promise<void> => {
    if (cvReady) return Promise.resolve();
    if (cvReadyPromise) return cvReadyPromise;

    cvReadyPromise = new Promise((resolve) => {
        if (cv.Mat) {
            cvReady = true;
            resolve();
        } else {
            cv.onRuntimeInitialized = () => {
                cvReady = true;
                resolve();
            };
        }
    });

    return cvReadyPromise;
};

export const isCvReady = (): boolean => cvReady;

// === å›¾åƒå¤„ç†ç®—æ³• ===

/**
 * é«˜æ–¯æ¨¡ç³Š - æ¯” Box Blur æ›´è‡ªç„¶çš„æ¨¡ç³Šæ•ˆæœ
 */
export const gaussianBlur = (
    imageData: ImageData,
    sigma: number = 2
): ImageData => {
    const src = cv.matFromImageData(imageData);
    const dst = new cv.Mat();

    // ğŸ’¡ ksize å¿…é¡»æ˜¯å¥‡æ•°ï¼Œsigma ç”¨äºæ§åˆ¶æ¨¡ç³Šç¨‹åº¦
    const ksize = new cv.Size(0, 0); // 0 è¡¨ç¤ºè‡ªåŠ¨ä» sigma è®¡ç®—
    cv.GaussianBlur(src, dst, ksize, sigma, sigma);

    const result = imageDataFromMat(dst);
    src.delete();
    dst.delete();
    return result;
};

/**
 * åŒè¾¹æ»¤æ³¢ - é™å™ªåŒæ—¶ä¿ç•™è¾¹ç¼˜ï¼ˆæ¯”ä¸­å€¼æ»¤æ³¢æ›´é€‚åˆä¹¦æ³•ï¼‰
 */
export const bilateralFilter = (
    imageData: ImageData,
    d: number = 9,
    sigmaColor: number = 75,
    sigmaSpace: number = 75
): ImageData => {
    const src = cv.matFromImageData(imageData);
    const dst = new cv.Mat();

    // ğŸ’¡ åŒè¾¹æ»¤æ³¢åœ¨å¹³æ»‘çº¹ç†çš„åŒæ—¶ä¿ç•™ç¬”ç”»è¾¹ç¼˜
    cv.bilateralFilter(src, dst, d, sigmaColor, sigmaSpace);

    const result = imageDataFromMat(dst);
    src.delete();
    dst.delete();
    return result;
};

/**
 * Canny è¾¹ç¼˜æ£€æµ‹ - ä¸“ä¸šçº§è¾¹ç¼˜æ£€æµ‹
 */
export const cannyEdgeDetection = (
    imageData: ImageData,
    threshold1: number = 50,
    threshold2: number = 150
): ImageData => {
    const src = cv.matFromImageData(imageData);
    const gray = new cv.Mat();
    const edges = new cv.Mat();
    const dst = new cv.Mat();

    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.Canny(gray, edges, threshold1, threshold2);
    cv.cvtColor(edges, dst, cv.COLOR_GRAY2RGBA);

    const result = imageDataFromMat(dst);
    src.delete();
    gray.delete();
    edges.delete();
    dst.delete();
    return result;
};

/**
 * ç›´æ–¹å›¾å‡è¡¡åŒ– - è‡ªåŠ¨ä¼˜åŒ–å¯¹æ¯”åº¦
 */
export const histogramEqualization = (imageData: ImageData): ImageData => {
    const src = cv.matFromImageData(imageData);
    const ycrcb = new cv.Mat();
    const channels = new cv.MatVector();
    const dst = new cv.Mat();

    // ğŸ’¡ åœ¨ YCrCb è‰²å½©ç©ºé—´çš„ Y é€šé“è¿›è¡Œå‡è¡¡åŒ–ï¼Œä¿æŒé¢œè‰²ä¸å¤±çœŸ
    cv.cvtColor(src, ycrcb, cv.COLOR_RGBA2RGB);
    const rgb = new cv.Mat();
    cv.cvtColor(src, rgb, cv.COLOR_RGBA2RGB);
    cv.cvtColor(rgb, ycrcb, cv.COLOR_RGB2YCrCb);
    cv.split(ycrcb, channels);
    cv.equalizeHist(channels.get(0), channels.get(0));
    cv.merge(channels, ycrcb);
    cv.cvtColor(ycrcb, rgb, cv.COLOR_YCrCb2RGB);
    cv.cvtColor(rgb, dst, cv.COLOR_RGB2RGBA);

    const result = imageDataFromMat(dst);
    src.delete();
    ycrcb.delete();
    channels.delete();
    rgb.delete();
    dst.delete();
    return result;
};

/**
 * è‡ªé€‚åº”é˜ˆå€¼ï¼ˆOpenCV ç‰ˆæœ¬ï¼‰ - æ›´æ™ºèƒ½çš„äºŒå€¼åŒ–
 */
export const adaptiveThreshold = (
    imageData: ImageData,
    blockSize: number = 11,
    C: number = 2
): ImageData => {
    const src = cv.matFromImageData(imageData);
    const gray = new cv.Mat();
    const binary = new cv.Mat();
    const dst = new cv.Mat();

    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.adaptiveThreshold(
        gray,
        binary,
        255,
        cv.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv.THRESH_BINARY_INV,
        blockSize,
        C
    );
    cv.cvtColor(binary, dst, cv.COLOR_GRAY2RGBA);

    const result = imageDataFromMat(dst);
    src.delete();
    gray.delete();
    binary.delete();
    dst.delete();
    return result;
};

/**
 * å½¢æ€å­¦æ“ä½œ - æ›´ç²¾ç»†çš„ç¬”ç”»ç²—ç»†æ§åˆ¶
 */
export const morphologyOperation = (
    imageData: ImageData,
    operation: 'dilate' | 'erode' | 'open' | 'close',
    kernelSize: number = 3
): ImageData => {
    const src = cv.matFromImageData(imageData);
    const dst = new cv.Mat();
    const kernel = cv.getStructuringElement(
        cv.MORPH_ELLIPSE,
        new cv.Size(kernelSize, kernelSize)
    );

    switch (operation) {
        case 'dilate':
            cv.dilate(src, dst, kernel);
            break;
        case 'erode':
            cv.erode(src, dst, kernel);
            break;
        case 'open':
            cv.morphologyEx(src, dst, cv.MORPH_OPEN, kernel);
            break;
        case 'close':
            cv.morphologyEx(src, dst, cv.MORPH_CLOSE, kernel);
            break;
    }

    const result = imageDataFromMat(dst);
    src.delete();
    dst.delete();
    kernel.delete();
    return result;
};

/**
 * é”åŒ– - ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­
 */
export const sharpen = (imageData: ImageData, amount: number = 1): ImageData => {
    const src = cv.matFromImageData(imageData);
    const dst = new cv.Mat();
    const blurred = new cv.Mat();

    cv.GaussianBlur(src, blurred, new cv.Size(0, 0), 3);
    cv.addWeighted(src, 1 + amount, blurred, -amount, 0, dst);

    const result = imageDataFromMat(dst);
    src.delete();
    dst.delete();
    blurred.delete();
    return result;
};

// === è¾…åŠ©å‡½æ•° ===

function imageDataFromMat(mat: any): ImageData {
    const data = new Uint8ClampedArray(mat.data);
    return new ImageData(data, mat.cols, mat.rows);
}

export default {
    initOpenCV,
    isCvReady,
    gaussianBlur,
    bilateralFilter,
    cannyEdgeDetection,
    histogramEqualization,
    adaptiveThreshold,
    morphologyOperation,
    sharpen,
};
